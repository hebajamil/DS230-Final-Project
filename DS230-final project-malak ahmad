{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+B9DBSLUgLInSC4KZLdXP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hebajamil/DS230-Final-Project/blob/main/Copy_of_Copy_of_Welcome_to_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in [\"user_prod_reorder_interaction\", \"log_prod_n_purchases\"]:\n",
        "    df_sample[col] = df_sample[col].fillna(df_sample[col].mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "Vu_Pe6Adtovb",
        "outputId": "cec6cd54-f617-465c-f1e5-9be7e9df28d5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_sample' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3707414778.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"user_prod_reorder_interaction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"log_prod_n_purchases\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_sample' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample.info()"
      ],
      "metadata": {
        "id": "WHyEy5YYt1kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_df = df_sample[df_sample[\"eval_set\"] == \"train\"].copy()"
      ],
      "metadata": {
        "id": "oThaeaCqt4pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_df.info()"
      ],
      "metadata": {
        "id": "vtZxPFeBt79r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode department inside model_df\n",
        "dept_dummies = pd.get_dummies(\n",
        "    model_df[\"department\"],\n",
        "    prefix=\"department\",\n",
        "    dtype=np.uint8\n",
        ")\n",
        "\n",
        "# (optional) one-hot encode part_of_day too, if you want to use it\n",
        "pod_dummies = pd.get_dummies(\n",
        "    model_df[\"part_of_day\"],\n",
        "    prefix=\"part_of_day\",\n",
        "    dtype=np.uint8\n",
        ")\n",
        "\n",
        "# Attach to model_df\n",
        "model_df = pd.concat([model_df, dept_dummies, pod_dummies], axis=1)"
      ],
      "metadata": {
        "id": "83F3bMTYt-zE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_cols = [\n",
        "    \"days_since_prior_order\",\n",
        "    \"days_since_prior_order_wr\",\n",
        "    \"add_to_cart_order_wr\",\n",
        "    \"is_weekend\",\n",
        "    \"order_hour_sin\",\n",
        "    \"order_hour_cos\",\n",
        "    \"user_n_orders\",\n",
        "    \"user_total_orders\",\n",
        "    \"user_avg_basket_size\",\n",
        "    \"user_total_items\",\n",
        "    \"user_reorder_ratio\",\n",
        "    \"user_mean_days_between_orders\",\n",
        "    \"user_last_order_number\",\n",
        "    \"user_last_order_recency\",\n",
        "    \"prod_n_orders\",\n",
        "    \"prod_n_purchases\",\n",
        "    \"prod_reorder_rate\",\n",
        "    \"prod_avg_cart_position\",\n",
        "    \"prod_first_order_num\",\n",
        "    \"prod_last_order_num\",\n",
        "    \"prod_mean_order_num\",\n",
        "    \"up_n_purchases\",\n",
        "    \"up_last_order_number\",\n",
        "    \"up_first_order_number\",\n",
        "    \"up_mean_add_to_cart\",\n",
        "    \"up_reorder_rate\",\n",
        "    \"up_last_purchase_cum_days\",\n",
        "    \"user_prod_reorder_interaction\",\n",
        "    \"log_prod_n_purchases\",\n",
        "]"
      ],
      "metadata": {
        "id": "I8Ru7Eg9uDAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_cols = [\n",
        "    \"product_id_te\",\n",
        "    \"user_id_te\",\n",
        "    \"product_id_fe\",\n",
        "    \"aisle_fe\",\n",
        "] + list(dept_dummies.columns) + list(pod_dummies.columns)"
      ],
      "metadata": {
        "id": "jlTy8ZN6uG_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "model_df[numeric_cols] = model_df[numeric_cols].fillna(\n",
        "    model_df[numeric_cols].mean(numeric_only=True)\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "model_df[numeric_cols] = scaler.fit_transform(model_df[numeric_cols])"
      ],
      "metadata": {
        "id": "1x9ZGjDnuPvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eatures = numeric_cols + encoded_cols\n",
        "X_all = model_df[features]\n",
        "y_all = model_df[\"reordered\"].astype(int)\n",
        "\n",
        "# sort by user + order_number to respect time\n",
        "model_df_sorted = model_df.sort_values([\"user_id\", \"order_number\"])\n",
        "order_nums = model_df_sorted[\"order_number\"]\n",
        "\n",
        "q_train = order_nums.quantile(0.7)\n",
        "q_val   = order_nums.quantile(0.85)\n",
        "\n",
        "train_mask = order_nums <= q_train\n",
        "val_mask   = (order_nums > q_train) & (order_nums <= q_val)\n",
        "test_mask  = order_nums > q_val\n",
        "\n",
        "X_train = model_df_sorted.loc[train_mask, features]\n",
        "y_train = model_df_sorted.loc[train_mask, \"reordered\"].astype(int)\n",
        "\n",
        "X_val   = model_df_sorted.loc[val_mask, features]\n",
        "y_val   = model_df_sorted.loc[val_mask, \"reordered\"].astype(int)\n",
        "\n",
        "X_test  = model_df_sorted.loc[test_mask, features]\n",
        "y_test  = model_df_sorted.loc[test_mask, \"reordered\"].astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "vrrD3aMyuQqX",
        "outputId": "20e67175-37f5-4131-ded9-84db419ae1bd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'numeric_cols' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3855877830.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumeric_cols\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mencoded_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reordered\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# sort by user + order_number to respect time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'numeric_cols' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "models = {\n",
        "    \"log_reg\": LogisticRegression(max_iter=1000, n_jobs=-1, solver=\"saga\"),\n",
        "    \"knn\": KNeighborsClassifier(),\n",
        "    \"svm_rbf\": SVC(kernel=\"rbf\", probability=True),\n",
        "    \"svm_linear\": LinearSVC(),\n",
        "    \"dt\": DecisionTreeClassifier(),\n",
        "    \"rf\": RandomForestClassifier(n_jobs=-1),\n",
        "    \"gb\": GradientBoostingClassifier(),\n",
        "    \"xgb\": XGBClassifier(\n",
        "        objective=\"binary:logistic\",\n",
        "        eval_metric=\"logloss\",\n",
        "        tree_method=\"hist\",\n",
        "        n_jobs=-1,\n",
        "        use_label_encoder=False\n",
        "    ),\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    \"log_reg\": {\n",
        "        \"C\": [0.01, 0.1, 1, 10],\n",
        "        \"penalty\": [\"l1\", \"l2\"],\n",
        "        \"class_weight\": [None, \"balanced\"],\n",
        "    },\n",
        "    \"knn\": {\n",
        "        \"n_neighbors\": [5, 15, 31],\n",
        "        \"weights\": [\"uniform\", \"distance\"],\n",
        "        \"p\": [1, 2],  # Manhattan vs Euclidean\n",
        "    },\n",
        "    \"svm_rbf\": {\n",
        "        \"C\": [0.1, 1, 10],\n",
        "        \"gamma\": [\"scale\", 0.01, 0.001],\n",
        "        # explain in report that SVM is expensive -> you limit grid + subsample\n",
        "    },\n",
        "    \"svm_linear\": {\n",
        "        \"C\": [0.01, 0.1, 1],\n",
        "    },\n",
        "    \"dt\": {\n",
        "        \"max_depth\": [None, 10, 20],\n",
        "        \"min_samples_split\": [2, 10, 50],\n",
        "    },\n",
        "    \"rf\": {\n",
        "        \"n_estimators\": [100, 300],\n",
        "        \"max_depth\": [None, 10, 20],\n",
        "        \"min_samples_split\": [2, 10],\n",
        "        \"class_weight\": [None, \"balanced_subsample\"],\n",
        "    },\n",
        "    \"gb\": {\n",
        "        \"n_estimators\": [100, 200],\n",
        "        \"learning_rate\": [0.05, 0.1],\n",
        "        \"max_depth\": [3, 5],\n",
        "    },\n",
        "    \"xgb\": {\n",
        "        \"n_estimators\": [200, 400],\n",
        "        \"learning_rate\": [0.05, 0.1],\n",
        "        \"max_depth\": [3, 5],\n",
        "        \"subsample\": [0.8, 1.0],\n",
        "        \"colsample_bytree\": [0.8, 1.0],from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "# If you use XGBoost or LightGBM:\n",
        "from xgboost import XGBClassifier\n",
        "# or from lightgbm import LGBMClassifier\n",
        "    },\n",
        "}"
      ],
      "metadata": {
        "id": "qkMaHVicuUlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=3)\n",
        "\n",
        "results = []\n",
        "best_models = {}      # <-- store best model for each name\n",
        "best_grids = {}       # optional: store the GridSearch objects too\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    grid = param_grids[name]\n",
        "\n",
        "    X_train_cv = X_train\n",
        "    y_train_cv = y_train\n",
        "\n",
        "    gs = GridSearchCV(\n",
        "        estimator=model,\n",
        "        param_grid=grid,\n",
        "        scoring=\"roc_auc\",\n",
        "        cv=tscv,\n",
        "        n_jobs=-1,\n",
        "        verbose=1\n",
        "    )\n",
        "    gs.fit(X_train_cv, y_train_cv)\n",
        "\n",
        "    best_model = gs.best_estimator_\n",
        "    best_models[name] = best_model      # <-- save it\n",
        "    best_grids[name] = gs               # <-- save the GridSearch (optional)\n",
        "\n",
        "    if hasattr(best_model, \"predict_proba\"):\n",
        "        y_val_proba = best_model.predict_proba(X_val)[:, 1]\n",
        "    else:\n",
        "        y_scores = best_model.decision_function(X_val)\n",
        "        # scale to 0-1 just for AUC\n",
        "        y_val_proba = (y_scores - y_scores.min()) / (y_scores.max() - y_scores.min())\n",
        "\n",
        "    val_auc = roc_auc_score(y_val, y_val_proba)\n",
        "\n",
        "    print(\"Best params:\", gs.best_params_)\n",
        "    print(\"Val AUC:\", val_auc)\n",
        "\n",
        "    results.append({\n",
        "        \"model\": name,\n",
        "        \"best_params\": gs.best_params_,\n",
        "        \"val_auc\": val_auc,\n",
        "    })"
      ],
      "metadata": {
        "id": "wEgwIJgVueWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_log_reg = best_models[\"log_reg\"]\n",
        "best_xgb     = best_models[\"xgb\"]"
      ],
      "metadata": {
        "id": "CmbqekkZuiRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outer_cv = TimeSeriesSplit(n_splits=3)\n",
        "inner_cv = TimeSeriesSplit(n_splits=3)\n",
        "\n",
        "xgb = models[\"xgb\"]\n",
        "xgb_params = param_grids[\"xgb\"]\n",
        "\n",
        "nested_auc_scores = []\n",
        "\n",
        "for train_idx, test_idx in outer_cv.split(X_train):\n",
        "    X_tr, X_te = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
        "    y_tr, y_te = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
        "\n",
        "    gs_inner = GridSearchCV(\n",
        "        estimator=xgb,\n",
        "        param_grid=xgb_params,\n",
        "        scoring=\"roc_auc\",\n",
        "        cv=inner_cv,\n",
        "        n_jobs=-1,\n",
        "        verbose=0\n",
        "    )\n",
        "    gs_inner.fit(X_tr, y_tr)\n",
        "\n",
        "    best_xgb = gs_inner.best_estimator_\n",
        "    y_te_proba = best_xgb.predict_proba(X_te)[:, 1]\n",
        "    auc_outer = roc_auc_score(y_te, y_te_proba)\n",
        "    nested_auc_scores.append(auc_outer)"
      ],
      "metadata": {
        "id": "nYD-LokKu03N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    confusion_matrix, ConfusionMatrixDisplay,\n",
        "    roc_curve, auc, precision_recall_curve\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def evaluate_classifier(name, model, X_tr, y_tr, X_val, y_val):\n",
        "    y_pred = model.predict(X_val)\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_proba = model.predict_proba(X_val)[:, 1]\n",
        "    else:\n",
        "        y_scores = model.decision_function(X_val)\n",
        "        # scale to [0,1] if you want\n",
        "        y_proba = (y_scores - y_scores.min()) / (y_scores.max() - y_scores.min())\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_val, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(cm)\n",
        "    disp.plot()\n",
        "    plt.title(f\"{name} - Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "    # ROC\n",
        "    fpr, tpr, _ = roc_curve(y_val, y_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f\"{name} (AUC={roc_auc:.3f})\")\n",
        "    plt.plot([0,1],[0,1],\"--\")\n",
        "    plt.xlabel(\"FPR\")\n",
        "    plt.ylabel(\"TPR\")\n",
        "    plt.title(\"ROC Curve\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # PR curve\n",
        "    precision, recall, _ = precision_recall_curve(y_val, y_proba)\n",
        "    plt.plot(recall, precision, label=name)\n",
        "    plt.xlabel(\"Recall\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.title(\"Precision-Recall Curve\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-d8fYfLfvJ5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_tree_importances(model, feature_names, top_n=20):\n",
        "    importances = model.feature_importances_\n",
        "    idx = np.argsort(importances)[-top_n:]\n",
        "    plt.barh(range(len(idx)), importances[idx])\n",
        "    plt.yticks(range(len(idx)), [feature_names[i] for i in idx])\n",
        "    plt.title(\"Tree-based Feature Importance\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_linear_coeffs(model, feature_names, top_n=20):\n",
        "    coefs = model.coef_.ravel()\n",
        "    idx = np.argsort(np.abs(coefs))[-top_n:]\n",
        "    plt.barh(range(len(idx)), coefs[idx])\n",
        "    plt.yticks(range(len(idx)), [feature_names[i] for i in idx])\n",
        "    plt.title(\"Linear Model Coefficients\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "G45vQoQVvRS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "# =============== TREE MODEL (XGBoost, RandomForest, etc.) ===============\n",
        "explainer_tree = shap.TreeExplainer(best_xgb)\n",
        "shap_vals_tree = explainer_tree.shap_values(X_val)\n",
        "\n",
        "shap.summary_plot(shap_vals_tree, X_val, feature_names=features)"
      ],
      "metadata": {
        "id": "j4y7X4oPvUTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============== LINEAR MODEL (Logistic Regression) ===================\n",
        "explainer_lin = shap.LinearExplainer(best_log_reg, X_train)\n",
        "shap_vals_lin = explainer_lin.shap_values(X_val)\n",
        "\n",
        "shap.summary_plot(shap_vals_lin, X_val, feature_names=features)"
      ],
      "metadata": {
        "id": "7O44uz6UvX_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "\n",
        "top3 = [\"user_reorder_ratio\", \"prod_reorder_rate\", \"user_prod_reorder_interaction\"]\n",
        "\n",
        "PartialDependenceDisplay.from_estimator(best_xgb, X_val, top3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9uNshTOmvdE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.metrics import brier_score_loss\n",
        "\n",
        "def calibration_analysis(model, X_val, y_val, name=\"model\"):\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        y_proba = model.predict_proba(X_val)[:, 1]\n",
        "    else:\n",
        "        y_scores = model.decision_function(X_val)\n",
        "        y_proba = (y_scores - y_scores.min()) / (y_scores.max() - y_scores.min())\n",
        "\n",
        "    prob_true, prob_pred = calibration_curve(y_val, y_proba, n_bins=10)\n",
        "    plt.plot(prob_pred, prob_true, marker=\"o\", label=name)\n",
        "    plt.plot([0,1],[0,1],\"--\")\n",
        "    plt.xlabel(\"Predicted probability\")\n",
        "    plt.ylabel(\"True fraction positives\")\n",
        "    plt.title(\"Calibration Plot\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    brier = brier_score_loss(y_val, y_proba)\n",
        "    print(f\"{name} Brier score: {brier:.4f}\")"
      ],
      "metadata": {
        "id": "Lj2olvwuvg99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "def plot_learning_curve(estimator, X, y, name=\"model\"):\n",
        "    train_sizes, train_scores, val_scores = learning_curve(\n",
        "        estimator, X, y,\n",
        "        train_sizes=np.linspace(0.1, 1.0, 5),\n",
        "        cv=3,\n",
        "        scoring=\"roc_auc\",\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    train_mean = train_scores.mean(axis=1)\n",
        "    val_mean = val_scores.mean(axis=1)\n",
        "\n",
        "    plt.plot(train_sizes, train_mean, label=\"Train AUC\")\n",
        "    plt.plot(train_sizes, val_mean, label=\"Val AUC\")\n",
        "    plt.xlabel(\"Training samples\")\n",
        "    plt.ylabel(\"AUC\")\n",
        "    plt.title(f\"Learning Curve - {name}\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "suDMx_jGvk_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# subsample for visual clarity\n",
        "sub_idx = np.random.choice(len(X_train), size=5000, replace=False)\n",
        "X_sub = X_train.iloc[sub_idx]\n",
        "y_sub = y_train.iloc[sub_idx]\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_sub_2d = pca.fit_transform(X_sub)\n",
        "\n",
        "def plot_decision_boundary_2d(clf, X2d, y, title):\n",
        "    x_min, x_max = X2d[:, 0].min() - 0.5, X2d[:, 0].max() + 0.5\n",
        "    y_min, y_max = X2d[:, 1].min() - 0.5, X2d[:, 1].max() + 0.5\n",
        "    xx, yy = np.meshgrid(\n",
        "        np.linspace(x_min, x_max, 200),\n",
        "        np.linspace(y_min, y_max, 200)\n",
        "    )\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "    cmap_light = ListedColormap([\"#FFAAAA\", \"#AAFFAA\"])\n",
        "    cmap_bold = ListedColormap([\"#FF0000\", \"#00FF00\"])\n",
        "    plt.contourf(xx, yy, Z, alpha=0.3, cmap=cmap_light)\n",
        "    plt.scatter(X2d[:, 0], X2d[:, 1], c=y, cmap=cmap_bold, s=5, alpha=0.7)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# train on 2D for boundary visualization only\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X2_train = X_sub_2d\n",
        "\n",
        "for clf_name, clf in [\n",
        "    (\"Logistic Regression\", LogisticRegression(max_iter=1000)),\n",
        "    (\"KNN\", KNeighborsClassifier(n_neighbors=15)),\n",
        "    (\"SVM RBF\", SVC(kernel=\"rbf\")),\n",
        "    (\"Decision Tree\", DecisionTreeClassifier(max_depth=5)),\n",
        "]:\n",
        "    clf.fit(X2_train, y_sub)\n",
        "    plot_decision_boundary_2d(clf, X2_train, y_sub, clf_name)"
      ],
      "metadata": {
        "id": "-fLkRkyIvptK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_df[\"reorder_count\"] = (\n",
        "    model_df\n",
        "    .groupby([\"user_id\", \"product_id\"])[\"reordered\"]\n",
        "    .transform(\"sum\")\n",
        "    .astype(float)\n",
        ")"
      ],
      "metadata": {
        "id": "TMcepE0fvu2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_features = numeric_cols + encoded_cols\n",
        "X_reg = model_df[reg_features]\n",
        "y_reg = model_df[\"reorder_count\"].astype(float)"
      ],
      "metadata": {
        "id": "AV8XvWmjv3O2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) sort AFTER creating reorder_count\n",
        "model_df_sorted = model_df.sort_values([\"user_id\", \"order_number\"])\n",
        "\n",
        "order_nums = model_df_sorted[\"order_number\"]\n",
        "\n",
        "q_train = order_nums.quantile(0.7)\n",
        "q_val   = order_nums.quantile(0.85)\n",
        "\n",
        "train_mask = order_nums <= q_train\n",
        "val_mask   = (order_nums > q_train) & (order_nums <= q_val)\n",
        "test_mask  = order_nums > q_val\n",
        "\n",
        "X_train_reg = model_df_sorted.loc[train_mask, reg_features]\n",
        "y_train_reg = model_df_sorted.loc[train_mask, \"reorder_count\"]\n",
        "\n",
        "X_val_reg   = model_df_sorted.loc[val_mask, reg_features]\n",
        "y_val_reg   = model_df_sorted.loc[val_mask, \"reorder_count\"]\n",
        "\n",
        "X_test_reg  = model_df_sorted.loc[test_mask, reg_features]\n",
        "y_test_reg  = model_df_sorted.loc[test_mask, \"reorder_count\"]"
      ],
      "metadata": {
        "id": "LoaFXNI4v4Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
        "from sklearn.svm import SVR, LinearSVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "reg_models = {\n",
        "    \"ols\": LinearRegression(),\n",
        "    \"lasso\": Lasso(max_iter=5000),\n",
        "    \"ridge\": Ridge(),\n",
        "    \"elastic\": ElasticNet(max_iter=5000),\n",
        "    \"svr_linear\": LinearSVR(max_iter=5000),\n",
        "    \"svr_rbf\": SVR(kernel=\"rbf\"),\n",
        "    \"knn\": KNeighborsRegressor(),\n",
        "    \"dt\": DecisionTreeRegressor(),\n",
        "    \"rf\": RandomForestRegressor(n_jobs=-1),\n",
        "    \"gbr\": GradientBoostingRegressor(),\n",
        "    \"xgbr\": XGBRegressor(\n",
        "        objective=\"reg:squarederror\",\n",
        "        tree_method=\"hist\",\n",
        "        n_jobs=-1\n",
        "    )\n",
        "}\n",
        "\n",
        "reg_param_grids = {\n",
        "    \"lasso\": {\"alpha\": [0.0001, 0.001, 0.01, 0.1]},\n",
        "    \"ridge\": {\"alpha\": [0.1, 1, 10, 50]},\n",
        "    \"elastic\": {\n",
        "        \"alpha\": [0.001, 0.01, 0.1],\n",
        "        \"l1_ratio\": [0.1, 0.5, 0.9]\n",
        "    },\n",
        "    \"svr_linear\": {\"C\": [0.1, 1, 10]},\n",
        "    \"svr_rbf\": {\n",
        "        \"C\": [1, 10],\n",
        "        \"gamma\": [\"scale\", 0.01]\n",
        "    },\n",
        "    \"knn\": {\n",
        "        \"n_neighbors\": [5, 15, 31],\n",
        "        \"weights\": [\"uniform\", \"distance\"]\n",
        "    },\n",
        "    \"dt\": {\n",
        "        \"max_depth\": [5, 10, 20],\n",
        "        \"min_samples_split\": [2, 10, 50]\n",
        "    },\n",
        "    \"rf\": {\n",
        "        \"n_estimators\": [100, 300],\n",
        "        \"max_depth\": [10, 20],\n",
        "        \"min_samples_split\": [2, 10]\n",
        "    },\n",
        "    \"gbr\": {\n",
        "        \"n_estimators\": [100, 200],\n",
        "        \"learning_rate\": [0.05, 0.1],\n",
        "        \"max_depth\": [3, 5]\n",
        "    },\n",
        "    \"xgbr\": {\n",
        "        \"n_estimators\": [200, 400],\n",
        "        \"learning_rate\": [0.05, 0.1],\n",
        "        \"max_depth\": [3, 6],\n",
        "        \"subsample\": [0.8, 1.0]\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "APRcj6hKwWcz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=3)\n",
        "reg_results = {}\n",
        "best_reg_models = {}\n",
        "\n",
        "for name, model in reg_models.items():\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "\n",
        "    # If no param grid (OLS)\n",
        "    grid = reg_param_grids.get(name, {})\n",
        "\n",
        "    gs = GridSearchCV(\n",
        "        model,\n",
        "        grid,\n",
        "        scoring=\"neg_mean_squared_error\",\n",
        "        cv=tscv,\n",
        "        n_jobs=-1,\n",
        "        verbose=1\n",
        "    )\n",
        "    gs.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "    best_model = gs.best_estimator_\n",
        "    best_reg_models[name] = best_model\n",
        "\n",
        "    preds = best_model.predict(X_val_reg)\n",
        "\n",
        "    reg_results[name] = {\n",
        "        \"best_params\": gs.best_params_,\n",
        "        \"MAE\": mean_absolute_error(y_val_reg, preds),\n",
        "        \"RMSE\": np.sqrt(mean_squared_error(y_val_reg, preds)),\n",
        "        \"R2\": r2_score(y_val_reg, preds)\n",
        "    }\n",
        "\n",
        "    print(reg_results[name])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "B0sJGcVfwbE2",
        "outputId": "1b3ebfad-e858-4775-a5ea-7cc957d5a13a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ols ===\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train_reg' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-439719148.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     )\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_reg' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adjusted_r2(r2, n, p):\n",
        "    return 1 - ((1-r2)*(n-1)/(n-p-1))\n",
        "\n",
        "for name, model in best_reg_models.items():\n",
        "    y_pred = model.predict(X_val_reg)\n",
        "\n",
        "    mae = mean_absolute_error(y_val_reg, y_pred)\n",
        "    mse = mean_squared_error(y_val_reg, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_val_reg, y_pred)\n",
        "    adj_r2 = adjusted_r2(r2, len(y_val_reg), X_val_reg.shape[1])\n",
        "\n",
        "    print(name, mae, rmse, r2, adj_r2)"
      ],
      "metadata": {
        "id": "mHPug55-weep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residuals = y_val_reg - y_pred\n",
        "plt.scatter(y_pred, residuals, s=2)\n",
        "plt.axhline(0, color=\"red\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.title(\"Residual Plot\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0lLTCtgewiDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
        "plt.title(\"Q-Q Plot\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zutzWaYKwlII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(residuals, bins=50)\n",
        "plt.title(\"Residual Distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QG0HZbKRwohK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.diagnostic import het_breuschpagan\n",
        "import statsmodels.api as sm\n",
        "\n",
        "exog = sm.add_constant(y_pred)\n",
        "bp_test = het_breuschpagan(residuals, exog)\n",
        "labels = [\"LM stat\", \"LM p-val\", \"F stat\", \"F p-val\"]\n",
        "\n",
        "for name, val in zip(labels, bp_test):\n",
        "    print(f\"{name}: {val}\")"
      ],
      "metadata": {
        "id": "ms1Y-0TZwryQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_xgbr = best_reg_models[\"xgbr\"]\n",
        "\n",
        "plt.barh(range(len(best_xgbr.feature_importances_)), best_xgbr.feature_importances_)\n",
        "plt.yticks(range(len(features)), features)\n",
        "plt.title(\"XGBoost Feature Importance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N5ozgBvowvgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_lasso = best_reg_models[\"lasso\"]\n",
        "\n",
        "coef = best_lasso.coef_\n",
        "plt.barh(range(len(coef)), coef)\n",
        "plt.yticks(range(len(features)), features)\n",
        "plt.title(\"Lasso Coefficients\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YkAPBEk_xKgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "explainer = shap.TreeExplainer(best_xgbr)\n",
        "shap_vals = explainer.shap_values(X_val_reg)\n",
        "\n",
        "shap.summary_plot(shap_vals, X_val_reg, feature_names=reg_features)"
      ],
      "metadata": {
        "id": "EQyLMecJxL4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = best_reg_models[\"xgbr\"]   # recommended final model\n",
        "\n",
        "y_test_pred = best_model.predict(X_test_reg)\n",
        "print(\"Test MAE:\", mean_absolute_error(y_test_reg, y_test_pred))\n",
        "print(\"Test RMSE:\", np.sqrt(mean_squared_error(y_test_reg, y_test_pred)))\n",
        "print(\"Test RÂ²:\", r2_score(y_test_reg, y_test_pred))"
      ],
      "metadata": {
        "id": "WfFhnc-dxQgg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
